{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTTxJj2hW9JH",
        "outputId": "d359df86-357b-42d7-d116-777952ee52a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AIO_Data_Analyst'...\n",
            "remote: Enumerating objects: 286, done.\u001b[K\n",
            "remote: Counting objects: 100% (286/286), done.\u001b[K\n",
            "remote: Compressing objects: 100% (205/205), done.\u001b[K\n",
            "remote: Total 286 (delta 106), reused 240 (delta 63), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (286/286), 2.40 MiB | 12.63 MiB/s, done.\n",
            "Resolving deltas: 100% (106/106), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/BachNgoH/AIO_Data_Analyst.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA with LLM"
      ],
      "metadata": {
        "id": "QzIl353OXQgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd AIO_Data_Analyst/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLCy5qHqXRBI",
        "outputId": "b50b419e-2c4f-4006-d004-193e91bba318"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AIO_Data_Analyst\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull -ff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlhQRjG3XVI9",
        "outputId": "b30981d3-229d-403a-f3b9-843a21c3a323"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YSWSWC5OXYAM",
        "outputId": "fc60ddfc-ce03-4bc0-ce5b-cb83b53cb7dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chainlit==1.1.301 (from -r requirements.txt (line 1))\n",
            "  Downloading chainlit-1.1.301-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-generativeai==0.5.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.5.4)\n",
            "Collecting pandasai==2.2.5 (from -r requirements.txt (line 3))\n",
            "  Downloading pandasai-2.2.5-py3-none-any.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.0/173.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index==0.10.44 (from -r requirements.txt (line 4))\n",
            "  Downloading llama_index-0.10.44-py3-none-any.whl (6.8 kB)\n",
            "Collecting llama-index-experimental==0.1.3 (from -r requirements.txt (line 5))\n",
            "  Downloading llama_index_experimental-0.1.3-py3-none-any.whl (11 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud==0.1.6 (from -r requirements.txt (line 6))\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
            "Collecting llama-index-llms-gemini==0.1.10 (from -r requirements.txt (line 7))\n",
            "  Downloading llama_index_llms_gemini-0.1.10-py3-none-any.whl (4.9 kB)\n",
            "Collecting llama-index-llms-groq==0.1.4 (from -r requirements.txt (line 8))\n",
            "  Downloading llama_index_llms_groq-0.1.4-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-llms-ollama==0.1.5 (from -r requirements.txt (line 9))\n",
            "  Downloading llama_index_llms_ollama-0.1.5-py3-none-any.whl (3.6 kB)\n",
            "Collecting llama-index-llms-openai==0.1.22 (from -r requirements.txt (line 10))\n",
            "  Downloading llama_index_llms_openai-0.1.22-py3-none-any.whl (11 kB)\n",
            "Collecting llama-index-llms-openai-like==0.1.3 (from -r requirements.txt (line 11))\n",
            "  Downloading llama_index_llms_openai_like-0.1.3-py3-none-any.whl (3.0 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai==0.1.6 (from -r requirements.txt (line 12))\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl (5.8 kB)\n",
            "Collecting llama-index-program-openai==0.1.6 (from -r requirements.txt (line 13))\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting python-dotenv==1.0.1 (from -r requirements.txt (line 14))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.9.0)\n",
            "Collecting seaborn==0.13.2 (from -r requirements.txt (line 16))\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0.0,>=23.1.0 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting asyncer<0.0.3,>=0.0.2 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading asyncer-0.0.2-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from chainlit==1.1.301->-r requirements.txt (line 1)) (8.1.7)\n",
            "Collecting dataclasses_json<0.6.0,>=0.5.7 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting fastapi<0.111.0,>=0.110.1 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filetype<2.0.0,>=1.2.0 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting httpx>=0.23.0 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lazify<0.5.0,>=0.4.0 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading Lazify-0.4.0-py2.py3-none-any.whl (3.1 kB)\n",
            "Collecting literalai==0.0.604 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading literalai-0.0.604.tar.gz (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from chainlit==1.1.301->-r requirements.txt (line 1)) (1.6.0)\n",
            "Collecting numpy<2.0,>=1.26 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.1 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from chainlit==1.1.301->-r requirements.txt (line 1)) (2.8.2)\n",
            "Collecting pyjwt<3.0.0,>=2.8.0 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Collecting python-multipart<0.0.10,>=0.0.9 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting python-socketio<6.0.0,>=5.11.0 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading python_socketio-5.11.3-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.38.0,>=0.37.2 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting syncer<3.0.0,>=2.0.3 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading syncer-2.0.3.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from chainlit==1.1.301->-r requirements.txt (line 1)) (2.0.1)\n",
            "Collecting uptrace<2.0.0,>=1.22.0 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading uptrace-1.24.0-py3-none-any.whl (8.6 kB)\n",
            "Collecting uvicorn<0.26.0,>=0.25.0 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading uvicorn-0.25.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles<0.21.0,>=0.20.0 (from chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading watchfiles-0.20.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.5.4->-r requirements.txt (line 2)) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.5.4->-r requirements.txt (line 2)) (2.16.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.5.4->-r requirements.txt (line 2)) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.5.4->-r requirements.txt (line 2)) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.5.4->-r requirements.txt (line 2)) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.5.4->-r requirements.txt (line 2)) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.5.4->-r requirements.txt (line 2)) (4.12.2)\n",
            "Collecting astor<0.9.0,>=0.8.1 (from pandasai==2.2.5->-r requirements.txt (line 3))\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: duckdb<1 in /usr/local/lib/python3.10/dist-packages (from pandasai==2.2.5->-r requirements.txt (line 3)) (0.10.3)\n",
            "Collecting faker<20.0.0,>=19.12.0 (from pandasai==2.2.5->-r requirements.txt (line 3))\n",
            "  Downloading Faker-19.13.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2<4.0.0,>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from pandasai==2.2.5->-r requirements.txt (line 3)) (3.1.4)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from pandasai==2.2.5->-r requirements.txt (line 3)) (3.7.1)\n",
            "Collecting openai<2 (from pandasai==2.2.5->-r requirements.txt (line 3))\n",
            "  Downloading openai-1.35.14-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.5.3 (from pandasai==2.2.5->-r requirements.txt (line 3))\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow<11.0.0,>=10.1.0 (from pandasai==2.2.5->-r requirements.txt (line 3))\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from pandasai==2.2.5->-r requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from pandasai==2.2.5->-r requirements.txt (line 3)) (1.11.4)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from pandasai==2.2.5->-r requirements.txt (line 3)) (2.0.31)\n",
            "Collecting sqlglot[rs]<26.0.0,>=25.0.3 (from pandasai==2.2.5->-r requirements.txt (line 3))\n",
            "  Downloading sqlglot-25.5.1-py3-none-any.whl (390 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.1/390.1 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading llama_index_agent_openai-0.2.8-py3-none-any.whl (13 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
            "Collecting llama-index-core==0.10.44 (from llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading llama_index_core-0.10.44-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading llama_index_readers_file-0.1.30-py3-none-any.whl (38 kB)\n",
            "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Collecting llamaindex-py-client<0.2.0,>=0.1.19 (from llama-index-indices-managed-llama-cloud==0.1.6->-r requirements.txt (line 6))\n",
            "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai-like==0.1.3->-r requirements.txt (line 11)) (4.41.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai==0.5.4->-r requirements.txt (line 2)) (1.24.0)\n",
            "Collecting chevron>=0.14.0 (from literalai==0.0.604->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading chevron-0.14.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4)) (6.0.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4)) (3.9.5)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4)) (2023.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4)) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4)) (3.8.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4)) (8.5.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect>=0.8.0 (from llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4)) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->pandasai==2.2.5->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->pandasai==2.2.5->-r requirements.txt (line 3)) (2023.4)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from asyncer<0.0.3,>=0.0.2->chainlit==1.1.301->-r requirements.txt (line 1)) (3.7.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses_json<0.6.0,>=0.5.7->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.5.4->-r requirements.txt (line 2)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.5.4->-r requirements.txt (line 2)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.5.4->-r requirements.txt (line 2)) (4.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit==1.1.301->-r requirements.txt (line 1)) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.23.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit==1.1.301->-r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit==1.1.301->-r requirements.txt (line 1)) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.23.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.3->pandasai==2.2.5->-r requirements.txt (line 3)) (2.1.5)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.44->-r requirements.txt (line 4)) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading pypdf-4.3.0-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading llama_parse-0.4.7-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai==2.2.5->-r requirements.txt (line 3)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai==2.2.5->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai==2.2.5->-r requirements.txt (line 3)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai==2.2.5->-r requirements.txt (line 3)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai==2.2.5->-r requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2->pandasai==2.2.5->-r requirements.txt (line 3)) (1.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->chainlit==1.1.301->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->chainlit==1.1.301->-r requirements.txt (line 1)) (2.20.1)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio<6.0.0,>=5.11.0->chainlit==1.1.301->-r requirements.txt (line 1)) (0.23.1)\n",
            "Collecting python-engineio>=4.8.0 (from python-socketio<6.0.0,>=5.11.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading python_engineio-4.9.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->pandasai==2.2.5->-r requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->pandasai==2.2.5->-r requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4->pandasai==2.2.5->-r requirements.txt (line 3)) (3.0.3)\n",
            "Collecting sqlglotrs==0.2.8 (from sqlglot[rs]<26.0.0,>=25.0.3->pandasai==2.2.5->-r requirements.txt (line 3))\n",
            "  Downloading sqlglotrs-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (332 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.9/332.9 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like==0.1.3->-r requirements.txt (line 11)) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like==0.1.3->-r requirements.txt (line 11)) (0.23.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like==0.1.3->-r requirements.txt (line 11)) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like==0.1.3->-r requirements.txt (line 11)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like==0.1.3->-r requirements.txt (line 11)) (0.4.3)\n",
            "Collecting opentelemetry-api~=1.24 (from uptrace<2.0.0,>=1.22.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp~=1.24 (from uptrace<2.0.0,>=1.22.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading opentelemetry_exporter_otlp-1.25.0-py3-none-any.whl (7.0 kB)\n",
            "Collecting opentelemetry-instrumentation~=0.45b0 (from uptrace<2.0.0,>=1.22.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
            "Collecting opentelemetry-sdk~=1.24 (from uptrace<2.0.0,>=1.22.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.5.4->-r requirements.txt (line 2)) (1.63.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.5.4->-r requirements.txt (line 2)) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.5.4->-r requirements.txt (line 2)) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.5.4->-r requirements.txt (line 2)) (4.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4)) (4.0.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.4.0->asyncer<0.0.3,>=0.0.2->chainlit==1.1.301->-r requirements.txt (line 1)) (1.2.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.44->-r requirements.txt (line 4)) (2.5)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.5.4->-r requirements.txt (line 2)) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.5.4->-r requirements.txt (line 2)) (1.48.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4)) (1.4.2)\n",
            "Collecting importlib-metadata<=7.1,>=6.0 (from opentelemetry-api~=1.24->uptrace<2.0.0,>=1.22.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.25.0 (from opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.25.0 (from opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.25.0-py3-none-any.whl (16 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation~=0.45b0->uptrace<2.0.0,>=1.22.0->chainlit==1.1.301->-r requirements.txt (line 1)) (67.7.2)\n",
            "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-sdk~=1.24->uptrace<2.0.0,>=1.22.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.5.4->-r requirements.txt (line 2)) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3->pandasai==2.2.5->-r requirements.txt (line 3)) (1.16.0)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.8.0->python-socketio<6.0.0,>=5.11.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading simple_websocket-1.0.0-py3-none-any.whl (13 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.44->llama-index==0.10.44->-r requirements.txt (line 4))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api~=1.24->uptrace<2.0.0,>=1.22.0->chainlit==1.1.301->-r requirements.txt (line 1)) (3.19.2)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio<6.0.0,>=5.11.0->chainlit==1.1.301->-r requirements.txt (line 1))\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: literalai, syncer\n",
            "  Building wheel for literalai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for literalai: filename=literalai-0.0.604-py3-none-any.whl size=60741 sha256=3f66573a85a544478e0441e2b9f75013ebe5bd0098841f203b55d8f581a4dc12\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/7a/94/a6ed7f613406b97e217393654a6aaabcc7023c1264f21ed4f1\n",
            "  Building wheel for syncer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syncer: filename=syncer-2.0.3-py2.py3-none-any.whl size=3436 sha256=1d69b576e13fd1c5a4ce76c742fdd41491d6b4e176f5a185b6307972f3479b05\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/e4/36/bcaad665bcc2b672888ff2df1a5a1dc638378d8765055313cd\n",
            "Successfully built literalai syncer\n",
            "Installing collected packages: syncer, striprtf, lazify, filetype, dirtyjson, chevron, sqlglotrs, sqlglot, python-multipart, python-dotenv, pypdf, pyjwt, pillow, packaging, opentelemetry-proto, numpy, mypy-extensions, importlib-metadata, h11, deprecated, astor, aiofiles, wsproto, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, pandas, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, marshmallow, httpcore, faker, asyncer, simple-websocket, opentelemetry-semantic-conventions, opentelemetry-instrumentation, httpx, fastapi, dataclasses_json, seaborn, python-engineio, opentelemetry-sdk, openai, llamaindex-py-client, literalai, python-socketio, pandasai, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, llama-index-legacy, llama-index-core, opentelemetry-exporter-otlp, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-llms-ollama, llama-index-indices-managed-llama-cloud, llama-index-experimental, llama-index-embeddings-openai, uptrace, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-llms-openai-like, llama-index-llms-gemini, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-llms-groq, chainlit, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: sqlglot\n",
            "    Found existing installation: sqlglot 20.11.0\n",
            "    Uninstalling sqlglot-20.11.0:\n",
            "      Successfully uninstalled sqlglot-20.11.0\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.0.0\n",
            "    Uninstalling importlib_metadata-8.0.0:\n",
            "      Successfully uninstalled importlib_metadata-8.0.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.13.1\n",
            "    Uninstalling seaborn-0.13.1:\n",
            "      Successfully uninstalled seaborn-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.11.1 requires sqlglot<=20.11,>=20.8.0, but you have sqlglot 25.5.1 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires sqlglot<=20.11,>=18.12.0, but you have sqlglot 25.5.1 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 astor-0.8.1 asyncer-0.0.2 chainlit-1.1.301 chevron-0.14.0 dataclasses_json-0.5.14 deprecated-1.2.14 dirtyjson-1.0.8 faker-19.13.0 fastapi-0.110.3 filetype-1.2.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 importlib-metadata-7.1.0 lazify-0.4.0 literalai-0.0.604 llama-index-0.10.44 llama-index-agent-openai-0.2.8 llama-index-cli-0.1.12 llama-index-core-0.10.44 llama-index-embeddings-openai-0.1.10 llama-index-experimental-0.1.3 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-gemini-0.1.10 llama-index-llms-groq-0.1.4 llama-index-llms-ollama-0.1.5 llama-index-llms-openai-0.1.22 llama-index-llms-openai-like-0.1.3 llama-index-multi-modal-llms-openai-0.1.6 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.30 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.7 llamaindex-py-client-0.1.19 marshmallow-3.21.3 mypy-extensions-1.0.0 numpy-1.26.4 openai-1.35.14 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-exporter-otlp-proto-http-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 packaging-23.2 pandas-1.5.3 pandasai-2.2.5 pillow-10.4.0 pyjwt-2.8.0 pypdf-4.3.0 python-dotenv-1.0.1 python-engineio-4.9.1 python-multipart-0.0.9 python-socketio-5.11.3 seaborn-0.13.2 simple-websocket-1.0.0 sqlglot-25.5.1 sqlglotrs-0.2.8 starlette-0.37.2 striprtf-0.0.26 syncer-2.0.3 tiktoken-0.7.0 typing-inspect-0.9.0 uptrace-1.24.0 uvicorn-0.25.0 watchfiles-0.20.0 wsproto-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "3b1c3eb3aedb47df812aac41e4f41f0f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "GOOGLE_API_KEY=\"YOUR_API_KEY\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwb5VFGeXY4X",
        "outputId": "d4219132-5c1c-4b0a-e2a8-c704a9f436aa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chainlit run app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "sOZ-ve1rXh5J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSAYYGEeXj7S",
        "outputId": "cec90406-dffc-481c-bf43-85d48adad9a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 34.147.99.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_8LOA5JXkjw",
        "outputId": "a67d3d9b-60e5-4c87-84d4-6aa06be08986"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 2.125s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 1 \u001b[93mmoderate\u001b[0m severity vulnerability\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5ThO0SRXppy",
        "outputId": "61849ad0-1e71-4ce9-e0d0-83511fe356a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.119s\n",
            "your url is: https://five-wombats-reply.loca.lt\n",
            "/root/.npm/_npx/1188/lib/node_modules/localtunnel/bin/lt.js:81\n",
            "    throw err;\n",
            "    ^\n",
            "\n",
            "Error: connection refused: localtunnel.me:42913 (check your firewall settings)\n",
            "    at Socket.<anonymous> (/root/.npm/_npx/1188/lib/node_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11)\n",
            "\u001b[90m    at Socket.emit (events.js:315:20)\u001b[39m\n",
            "\u001b[90m    at emitErrorNT (internal/streams/destroy.js:106:8)\u001b[39m\n",
            "\u001b[90m    at emitErrorCloseNT (internal/streams/destroy.js:74:3)\u001b[39m\n",
            "\u001b[90m    at processTicksAndRejections (internal/process/task_queues.js:80:21)\u001b[39m\n"
          ]
        }
      ]
    }
  ]
}